{
  "_metadata": {
    "capturedAt": "2026-01-10T12:00:00.000Z",
    "model": "mock",
    "scenario": "verification-with-replicates",
    "backendUrl": "http://localhost:5001",
    "isMocked": true,
    "description": "Verification results with replicate_count=3, showing multiple replicates per question"
  },
  "data": {
    "q1_anthropic/claude-haiku-4-5_anthropic/claude-haiku-4-5_1768041830000_replicate_0": {
      "metadata": {
        "question_id": "q1",
        "template_id": "fcb63001d642141a76ea74a28088cc3a",
        "completed_without_errors": true,
        "error": null,
        "question_text": "What is the capital of France?",
        "raw_answer": "The capital of France is Paris.",
        "keywords": null,
        "answering_model": "anthropic/claude-haiku-4-5",
        "parsing_model": "anthropic/claude-haiku-4-5",
        "answering_system_prompt": "You are a helpful assistant.",
        "parsing_system_prompt": "You are a helpful assistant.",
        "execution_time": 1.523,
        "timestamp": "2026-01-10 12:00:00",
        "result_id": "mock-result-q1-r0",
        "run_name": "replicate-verification",
        "replicate": 0
      },
      "template": {
        "raw_llm_response": "The capital of France is Paris.",
        "parsed_gt_response": { "capital": "Paris" },
        "parsed_llm_response": { "capital": "Paris" },
        "template_verification_performed": true,
        "verify_result": true,
        "verify_granular_result": { "capital_match": true },
        "abstention_check_performed": true,
        "abstention_detected": false
      },
      "rubric": null,
      "deep_judgment": null,
      "deep_judgment_rubric": null,
      "evaluation_input": null,
      "used_full_trace": true,
      "trace_extraction_error": null
    },
    "q1_anthropic/claude-haiku-4-5_anthropic/claude-haiku-4-5_1768041830100_replicate_1": {
      "metadata": {
        "question_id": "q1",
        "template_id": "fcb63001d642141a76ea74a28088cc3a",
        "completed_without_errors": true,
        "error": null,
        "question_text": "What is the capital of France?",
        "raw_answer": "The capital of France is Paris.",
        "keywords": null,
        "answering_model": "anthropic/claude-haiku-4-5",
        "parsing_model": "anthropic/claude-haiku-4-5",
        "answering_system_prompt": "You are a helpful assistant.",
        "parsing_system_prompt": "You are a helpful assistant.",
        "execution_time": 1.412,
        "timestamp": "2026-01-10 12:00:01",
        "result_id": "mock-result-q1-r1",
        "run_name": "replicate-verification",
        "replicate": 1
      },
      "template": {
        "raw_llm_response": "Paris is the capital city of France.",
        "parsed_gt_response": { "capital": "Paris" },
        "parsed_llm_response": { "capital": "Paris" },
        "template_verification_performed": true,
        "verify_result": true,
        "verify_granular_result": { "capital_match": true },
        "abstention_check_performed": true,
        "abstention_detected": false
      },
      "rubric": null,
      "deep_judgment": null,
      "deep_judgment_rubric": null,
      "evaluation_input": null,
      "used_full_trace": true,
      "trace_extraction_error": null
    },
    "q1_anthropic/claude-haiku-4-5_anthropic/claude-haiku-4-5_1768041830200_replicate_2": {
      "metadata": {
        "question_id": "q1",
        "template_id": "fcb63001d642141a76ea74a28088cc3a",
        "completed_without_errors": true,
        "error": null,
        "question_text": "What is the capital of France?",
        "raw_answer": "The capital of France is Paris.",
        "keywords": null,
        "answering_model": "anthropic/claude-haiku-4-5",
        "parsing_model": "anthropic/claude-haiku-4-5",
        "answering_system_prompt": "You are a helpful assistant.",
        "parsing_system_prompt": "You are a helpful assistant.",
        "execution_time": 1.387,
        "timestamp": "2026-01-10 12:00:02",
        "result_id": "mock-result-q1-r2",
        "run_name": "replicate-verification",
        "replicate": 2
      },
      "template": {
        "raw_llm_response": "France's capital is Paris.",
        "parsed_gt_response": { "capital": "Paris" },
        "parsed_llm_response": { "capital": "Paris" },
        "template_verification_performed": true,
        "verify_result": true,
        "verify_granular_result": { "capital_match": true },
        "abstention_check_performed": true,
        "abstention_detected": false
      },
      "rubric": null,
      "deep_judgment": null,
      "deep_judgment_rubric": null,
      "evaluation_input": null,
      "used_full_trace": true,
      "trace_extraction_error": null
    },
    "q2_anthropic/claude-haiku-4-5_anthropic/claude-haiku-4-5_1768041830300_replicate_0": {
      "metadata": {
        "question_id": "q2",
        "template_id": "9fb7f87b18c8c14e2203e010aa6d05de",
        "completed_without_errors": true,
        "error": null,
        "question_text": "Calculate 15 + 27.",
        "raw_answer": "42",
        "keywords": null,
        "answering_model": "anthropic/claude-haiku-4-5",
        "parsing_model": "anthropic/claude-haiku-4-5",
        "answering_system_prompt": "You are a helpful assistant.",
        "parsing_system_prompt": "You are a helpful assistant.",
        "execution_time": 0.987,
        "timestamp": "2026-01-10 12:00:03",
        "result_id": "mock-result-q2-r0",
        "run_name": "replicate-verification",
        "replicate": 0
      },
      "template": {
        "raw_llm_response": "15 + 27 = 42",
        "parsed_gt_response": { "result": 42 },
        "parsed_llm_response": { "result": 42 },
        "template_verification_performed": true,
        "verify_result": true,
        "verify_granular_result": { "result_match": true },
        "abstention_check_performed": true,
        "abstention_detected": false
      },
      "rubric": null,
      "deep_judgment": null,
      "deep_judgment_rubric": null,
      "evaluation_input": null,
      "used_full_trace": true,
      "trace_extraction_error": null
    },
    "q2_anthropic/claude-haiku-4-5_anthropic/claude-haiku-4-5_1768041830400_replicate_1": {
      "metadata": {
        "question_id": "q2",
        "template_id": "9fb7f87b18c8c14e2203e010aa6d05de",
        "completed_without_errors": true,
        "error": null,
        "question_text": "Calculate 15 + 27.",
        "raw_answer": "42",
        "keywords": null,
        "answering_model": "anthropic/claude-haiku-4-5",
        "parsing_model": "anthropic/claude-haiku-4-5",
        "answering_system_prompt": "You are a helpful assistant.",
        "parsing_system_prompt": "You are a helpful assistant.",
        "execution_time": 1.023,
        "timestamp": "2026-01-10 12:00:04",
        "result_id": "mock-result-q2-r1",
        "run_name": "replicate-verification",
        "replicate": 1
      },
      "template": {
        "raw_llm_response": "The sum of 15 and 27 is 42.",
        "parsed_gt_response": { "result": 42 },
        "parsed_llm_response": { "result": 42 },
        "template_verification_performed": true,
        "verify_result": true,
        "verify_granular_result": { "result_match": true },
        "abstention_check_performed": true,
        "abstention_detected": false
      },
      "rubric": null,
      "deep_judgment": null,
      "deep_judgment_rubric": null,
      "evaluation_input": null,
      "used_full_trace": true,
      "trace_extraction_error": null
    },
    "q2_anthropic/claude-haiku-4-5_anthropic/claude-haiku-4-5_1768041830500_replicate_2": {
      "metadata": {
        "question_id": "q2",
        "template_id": "9fb7f87b18c8c14e2203e010aa6d05de",
        "completed_without_errors": false,
        "error": "Parsing error: invalid format",
        "question_text": "Calculate 15 + 27.",
        "raw_answer": "42",
        "keywords": null,
        "answering_model": "anthropic/claude-haiku-4-5",
        "parsing_model": "anthropic/claude-haiku-4-5",
        "answering_system_prompt": "You are a helpful assistant.",
        "parsing_system_prompt": "You are a helpful assistant.",
        "execution_time": 0.765,
        "timestamp": "2026-01-10 12:00:05",
        "result_id": "mock-result-q2-r2",
        "run_name": "replicate-verification",
        "replicate": 2
      },
      "template": {
        "raw_llm_response": "Let me calculate: 15 + 27 = 42",
        "parsed_gt_response": { "result": 42 },
        "parsed_llm_response": null,
        "template_verification_performed": true,
        "verify_result": false,
        "verify_granular_result": null,
        "abstention_check_performed": true,
        "abstention_detected": false
      },
      "rubric": null,
      "deep_judgment": null,
      "deep_judgment_rubric": null,
      "evaluation_input": null,
      "used_full_trace": true,
      "trace_extraction_error": null
    },
    "q3_anthropic/claude-haiku-4-5_anthropic/claude-haiku-4-5_1768041830600_replicate_0": {
      "metadata": {
        "question_id": "q3",
        "template_id": "0ece68c26113df796e88f7a1312bf830",
        "completed_without_errors": true,
        "error": null,
        "question_text": "Name three primary colors.",
        "raw_answer": "Red, blue, and yellow.",
        "keywords": null,
        "answering_model": "anthropic/claude-haiku-4-5",
        "parsing_model": "anthropic/claude-haiku-4-5",
        "answering_system_prompt": "You are a helpful assistant.",
        "parsing_system_prompt": "You are a helpful assistant.",
        "execution_time": 0.876,
        "timestamp": "2026-01-10 12:00:06",
        "result_id": "mock-result-q3-r0",
        "run_name": "replicate-verification",
        "replicate": 0
      },
      "template": {
        "raw_llm_response": "The three primary colors are red, blue, and yellow.",
        "parsed_gt_response": { "colors": ["red", "blue", "yellow"] },
        "parsed_llm_response": { "colors": ["red", "blue", "yellow"] },
        "template_verification_performed": true,
        "verify_result": true,
        "verify_granular_result": { "all_colors_present": true },
        "abstention_check_performed": true,
        "abstention_detected": false
      },
      "rubric": null,
      "deep_judgment": null,
      "deep_judgment_rubric": null,
      "evaluation_input": null,
      "used_full_trace": true,
      "trace_extraction_error": null
    },
    "q3_anthropic/claude-haiku-4-5_anthropic/claude-haiku-4-5_1768041830700_replicate_1": {
      "metadata": {
        "question_id": "q3",
        "template_id": "0ece68c26113df796e88f7a1312bf830",
        "completed_without_errors": true,
        "error": null,
        "question_text": "Name three primary colors.",
        "raw_answer": "Red, blue, and yellow.",
        "keywords": null,
        "answering_model": "anthropic/claude-haiku-4-5",
        "parsing_model": "anthropic/claude-haiku-4-5",
        "answering_system_prompt": "You are a helpful assistant.",
        "parsing_system_prompt": "You are a helpful assistant.",
        "execution_time": 0.912,
        "timestamp": "2026-01-10 12:00:07",
        "result_id": "mock-result-q3-r1",
        "run_name": "replicate-verification",
        "replicate": 1
      },
      "template": {
        "raw_llm_response": "Red, blue, and yellow are the primary colors.",
        "parsed_gt_response": { "colors": ["red", "blue", "yellow"] },
        "parsed_llm_response": { "colors": ["red", "blue", "yellow"] },
        "template_verification_performed": true,
        "verify_result": true,
        "verify_granular_result": { "all_colors_present": true },
        "abstention_check_performed": true,
        "abstention_detected": false
      },
      "rubric": null,
      "deep_judgment": null,
      "deep_judgment_rubric": null,
      "evaluation_input": null,
      "used_full_trace": true,
      "trace_extraction_error": null
    },
    "q3_anthropic/claude-haiku-4-5_anthropic/claude-haiku-4-5_1768041830800_replicate_2": {
      "metadata": {
        "question_id": "q3",
        "template_id": "0ece68c26113df796e88f7a1312bf830",
        "completed_without_errors": true,
        "error": null,
        "question_text": "Name three primary colors.",
        "raw_answer": "Red, blue, and yellow.",
        "keywords": null,
        "answering_model": "anthropic/claude-haiku-4-5",
        "parsing_model": "anthropic/claude-haiku-4-5",
        "answering_system_prompt": "You are a helpful assistant.",
        "parsing_system_prompt": "You are a helpful assistant.",
        "execution_time": 0.834,
        "timestamp": "2026-01-10 12:00:08",
        "result_id": "mock-result-q3-r2",
        "run_name": "replicate-verification",
        "replicate": 2
      },
      "template": {
        "raw_llm_response": "Primary colors: red, blue, yellow.",
        "parsed_gt_response": { "colors": ["red", "blue", "yellow"] },
        "parsed_llm_response": { "colors": ["red", "blue", "yellow"] },
        "template_verification_performed": true,
        "verify_result": true,
        "verify_granular_result": { "all_colors_present": true },
        "abstention_check_performed": true,
        "abstention_detected": false
      },
      "rubric": null,
      "deep_judgment": null,
      "deep_judgment_rubric": null,
      "evaluation_input": null,
      "used_full_trace": true,
      "trace_extraction_error": null
    }
  }
}
